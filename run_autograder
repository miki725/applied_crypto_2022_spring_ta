#!/usr/bin/env bash

# gradescope rules
# see https://gradescope-autograders.readthedocs.io/en/latest/specs/
#
# results/results.json
#   grade results

SOURCE=$PWD/source
SUBMISSION=$PWD/submission
RESULTS=$PWD/results
CONFIG=$SOURCE/config.sh
SETUP=$SUBMISSION/setup.sh

if [ -f $CONFIG ]; then
    source $CONFIG
fi

ARTIFACTS_JSON=$SOURCE/_artifacts.json
INPUT_JSON=$SOURCE/_input.json
OUTPUT_JSON=$SOURCE/_output.json
REFERENCE_JSON=$SOURCE/_reference.json
REPORT_JSON=$RESULTS/results.json
ERRORS=$SOURCE/_errors.log

ARTIFACTS_BIN="python3 $SOURCE/artifacts.py"
INPUT_BIN="python3 $SOURCE/input.py"
SOLUTION_BIN="python3 $SOURCE/solution.py"
BIN=${BIN:-ps*}
export PS=$SUBMISSION/$BIN

exec 2> $RESULTS/stderr

set -x

mkdir -p $RESULTS
cat > $REPORT_JSON <<EOF
{
    "stdout_visibility": "visible",
    "score": 0,
    "output": "submitted script failed to run"
}
EOF

rm -rf $SOURCE/*.json $SOURCE/*.log || true

if [ -f $SETUP ]; then
    chmod +x $SETUP
    (
        cd $(dirname $SETUP)
        ./$(basename $SETUP)
    )
fi

if [ -f $PS ]; then
    chmod +x $PS
fi

if [ -z "$NO_INPUT" ]; then

    # if we use artifacts for grading, then we generate artifacts file
    # otherwise we use input.py to generate input data
    # and shold rely on sample solution below
    if $ARTIFACTS_BIN > $ARTIFACTS_JSON; then
        $INPUT_BIN \
            < $ARTIFACTS_JSON \
            > $INPUT_JSON
    else
        $INPUT_BIN \
            > $INPUT_JSON
    fi

    $PS \
        < $INPUT_JSON \
        > $OUTPUT_JSON \
        2> $ERRORS \
        || (
            echo "$BIN exited with an error. autograding cannot grade this submission"
            echo
            cat $ERRORS;
            exit 1
        ) \
        || exit 0

    cat $OUTPUT_JSON \
        | python3 -m json.tool \
        > /dev/null \
        || (
            echo "$BIN produced invalid json output:"
            echo
            cat $OUTPUT_JSON
            exit 1
        ) \
        || exit 0

    # solution might not exist
    # and instead grading might rely on artifacts file
    $SOLUTION_BIN \
        < $INPUT_JSON \
        > $REFERENCE_JSON \
        || true

    pytest $SOURCE/tests* \
        --verbose --verbose \
        --disable-pytest-warnings \
        --no-header \
        --capture=no \
        $PYTEST_FLAGS \
        2> $REPORT_JSON \
        || true

    echo
    echo tests used input json:

    cat $INPUT_JSON | python3 -m json.tool

    echo
    echo $BIN generated json:

    cat $OUTPUT_JSON | python3 -m json.tool

else

    pytest $SOURCE/tests* \
        --verbose --verbose \
        --disable-pytest-warnings \
        --no-header \
        --capture=no \
        $PYTEST_FLAGS \
        2> $REPORT_JSON \
        || true

fi
